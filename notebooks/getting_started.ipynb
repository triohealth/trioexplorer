{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Getting Started with Notesearch API\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/notesearch/blob/main/notebooks/getting_started.ipynb)\n\nThis notebook demonstrates how to use the Notesearch API to search clinical notes across patient cohorts. You will learn how to:\n\n1. Configure API authentication\n2. Discover available indexed cohorts\n3. Perform different types of searches (keyword, semantic, hybrid)\n4. Apply date and other filters to search queries\n5. Visualize search results and performance metrics\n\n## Prerequisites\n\n**You will need:**\n- An API key with `read:global` or cohort-specific `read:<cohort-id>` entitlements\n- Contact your administrator to obtain an API key"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install -q requests pandas matplotlib seaborn\n\n# Import dependencies\nimport requests\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, Any, List\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure matplotlib for notebook display\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\nprint(\"✓ All dependencies loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\n\n# Production API Endpoints\n# TODO: Update these URLs with your production endpoints\nSEARCH_API_URL = \"https://search.notesearch.example.com\"\n\nprint(f\"Search API: {SEARCH_API_URL}\")\n\n# API Key Configuration\n# Option 1 (Recommended): Use Colab secrets\ntry:\n    from google.colab import userdata\n    API_KEY = userdata.get('NOTESEARCH_API_KEY')\n    print(\"✓ API key loaded from Colab secrets\")\nexcept:\n    # Option 2: Set directly (not recommended - use Colab secrets instead)\n    API_KEY = os.environ.get(\"NOTESEARCH_API_KEY\", \"\")\n    if not API_KEY:\n        print(\"⚠️  WARNING: No API key configured!\")\n        print(\"Add NOTESEARCH_API_KEY to Colab secrets, or set it manually:\")\n        print(\"API_KEY = 'ts_your_api_key_here'\")\n    else:\n        print(f\"✓ API Key configured: {API_KEY[:8]}...\")\n\n# Test connectivity\ndef check_service_health(url: str, name: str) -> bool:\n    \"\"\"Check if the API service is healthy and reachable.\"\"\"\n    try:\n        response = requests.get(f\"{url}/health\", timeout=5)\n        if response.status_code == 200:\n            print(f\"✓ {name} is healthy\")\n            return True\n        else:\n            print(f\"✗ {name} returned status {response.status_code}\")\n            return False\n    except requests.exceptions.ConnectionError:\n        print(f\"✗ Cannot connect to {name} at {url}\")\n        print(\"  Contact your administrator if this persists\")\n        return False\n    except Exception as e:\n        print(f\"✗ Error checking {name}: {str(e)}\")\n        return False\n\nprint(\"\\nChecking API connectivity...\")\nsearch_healthy = check_service_health(SEARCH_API_URL, \"Search API\")\n\nif search_healthy:\n    print(\"\\n✓ All systems ready!\")\nelse:\n    print(\"\\n⚠️  Search API is not available. Check the errors above.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Discover Available Cohorts\n\nBefore searching, you need to know which cohorts are indexed and available. The `/cohorts/indexed` endpoint lists all cohorts with searchable data in Turbopuffer.\n\nEach indexed cohort includes:\n- `cohort_id` - Unique identifier\n- `cohort_name` - Human-readable name (if available)\n- `namespace` - Turbopuffer namespace for the index\n- `chunk_count` - Number of indexed chunks (vectors)\n- `index_status` - Current indexing status"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_indexed_cohorts(limit: int = 20) -> List[Dict[str, Any]]:\n    \"\"\"\n    List all indexed cohorts available for search.\n\n    Args:\n        limit: Maximum number of cohorts to return (max 100)\n\n    Returns:\n        List of indexed cohort information\n    \"\"\"\n    response = requests.get(\n        f\"{SEARCH_API_URL}/cohorts/indexed\",\n        headers={\"X-API-Key\": API_KEY},\n        params={\"limit\": limit}\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        cohorts = data.get(\"items\", [])\n        total = data.get(\"total_count\", len(cohorts))\n        print(f\"Found {total} indexed cohorts (showing {len(cohorts)})\")\n        return cohorts\n    else:\n        print(f\"Failed to list cohorts: {response.status_code}\")\n        print(response.text)\n        return []\n\n# Fetch indexed cohorts\ncohorts = get_indexed_cohorts()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display cohorts as a formatted table\nif cohorts:\n    cohorts_df = pd.DataFrame(cohorts)\n\n    # Format the display\n    display_cols = [\"cohort_id\", \"cohort_name\", \"chunk_count\", \"index_status\"]\n    available_cols = [c for c in display_cols if c in cohorts_df.columns]\n\n    print(\"\\nIndexed Cohorts:\")\n    print(\"-\" * 80)\n    display(cohorts_df[available_cols].style.format({\n        \"chunk_count\": \"{:,}\"\n    }))\n\n    # Summary statistics\n    total_chunks = cohorts_df[\"chunk_count\"].sum()\n    print(f\"\\nTotal indexed chunks across all cohorts: {total_chunks:,}\")\nelse:\n    print(\"No cohorts available. Ensure data has been indexed.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Search a Cohort\n\nThe Search API supports three search modes:\n\n| Mode | Description | Best For |\n|------|-------------|----------|\n| `keyword` | BM25 full-text search | Exact terms, medical codes (e.g., \"ICD-10 E11.9\") |\n| `semantic` | Vector similarity search | Conceptual queries (e.g., \"patient struggling with blood sugar\") |\n| `hybrid` (default) | Combines both with reciprocal rank fusion | General-purpose queries |\n\n### Key Parameters\n\n- `query` (required) - Search text\n- `search-type` - Search mode (default: `hybrid`)\n- `k` - Number of results (default: 10, max: 300)\n- `cohort-ids` - Comma-separated cohort IDs to search\n- `rerank` - Apply Cohere reranking (default: true)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    query: str,\n",
    "    search_type: str = \"hybrid\",\n",
    "    k: int = 10,\n",
    "    cohort_ids: Optional[List[str]] = None,\n",
    "    rerank: bool = True,\n",
    "    date_from: Optional[str] = None,\n",
    "    date_to: Optional[str] = None,\n",
    "    note_types: Optional[List[str]] = None,\n",
    "    include_noise: bool = False,\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search indexed patient notes.\n",
    "\n",
    "    Args:\n",
    "        query: Search text\n",
    "        search_type: 'keyword', 'semantic', or 'hybrid' (default)\n",
    "        k: Number of results to return (max 300)\n",
    "        cohort_ids: List of cohort IDs to search\n",
    "        rerank: Apply Cohere reranking (default True, hybrid only)\n",
    "        date_from: Filter from date (YYYY-MM-DD)\n",
    "        date_to: Filter to date (YYYY-MM-DD)\n",
    "        note_types: Filter by note types\n",
    "        include_noise: Include noise notes (default False)\n",
    "\n",
    "    Returns:\n",
    "        Search response with results and metadata\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"search-type\": search_type,\n",
    "        \"k\": k,\n",
    "        \"rerank\": str(rerank).lower(),\n",
    "        \"include-noise\": str(include_noise).lower(),\n",
    "    }\n",
    "\n",
    "    if cohort_ids:\n",
    "        params[\"cohort-ids\"] = \",\".join(str(c) for c in cohort_ids)\n",
    "    if date_from:\n",
    "        params[\"date-from\"] = date_from\n",
    "    if date_to:\n",
    "        params[\"date-to\"] = date_to\n",
    "    if note_types:\n",
    "        params[\"note-types\"] = \",\".join(note_types)\n",
    "\n",
    "    # Add any additional parameters\n",
    "    for key, value in kwargs.items():\n",
    "        params[key.replace(\"_\", \"-\")] = value\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"{SEARCH_API_URL}/search\",\n",
    "        headers={\"X-API-Key\": API_KEY},\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Search failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return {\"results\": [], \"metadata\": {}}\n",
    "\n",
    "# Example search\n",
    "results = search(\"diabetes management\", k=10)\n",
    "print(f\"Found {len(results.get('results', []))} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(response: Dict[str, Any], show_text: bool = False):\n",
    "    \"\"\"Display search results in a formatted table.\"\"\"\n",
    "    results = response.get(\"results\", [])\n",
    "    metadata = response.get(\"metadata\", {})\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SEARCH RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Metadata summary\n",
    "    print(f\"\\nQuery: '{metadata.get('query', 'N/A')}'\")\n",
    "    print(f\"Search Type: {metadata.get('search_type', 'N/A')}\")\n",
    "    print(f\"Total Results: {metadata.get('total_results', 0)}\")\n",
    "    print(f\"Reranked: {metadata.get('reranked', False)}\")\n",
    "    print(f\"Distance Threshold: {metadata.get('distance_threshold', 'N/A')}\")\n",
    "\n",
    "    # Match counts\n",
    "    exact = metadata.get('exact_match_count')\n",
    "    semantic = metadata.get('semantic_match_count')\n",
    "    if exact is not None or semantic is not None:\n",
    "        print(f\"\\nMatch Counts:\")\n",
    "        if exact is not None:\n",
    "            print(f\"  Keyword (BM25): {exact:,}\")\n",
    "        if semantic is not None:\n",
    "            print(f\"  Semantic (Vector): {semantic:,}\")\n",
    "\n",
    "    # Unique counts\n",
    "    print(f\"\\nUnique Entities:\")\n",
    "    print(f\"  Patients: {metadata.get('unique_patients', 'N/A')}\")\n",
    "    print(f\"  Encounters: {metadata.get('unique_encounters', 'N/A')}\")\n",
    "    print(f\"  Notes: {metadata.get('unique_notes', 'N/A')}\")\n",
    "\n",
    "    # Omitted results (noise filtering)\n",
    "    omitted = metadata.get('omitted_results')\n",
    "    if omitted:\n",
    "        print(f\"\\nOmitted (Noise Filtered):\")\n",
    "        print(f\"  Semantic: {omitted.get('semantic_omitted', 0)}\")\n",
    "        print(f\"  Keyword: {omitted.get('keyword_omitted', 0)}\")\n",
    "        print(f\"  Total: {omitted.get('total_omitted', 0)}\")\n",
    "        if omitted.get('is_minimum'):\n",
    "            print(\"  (counts are minimum estimates)\")\n",
    "\n",
    "    # Results table\n",
    "    if results:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"TOP RESULTS\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        for i, result in enumerate(results[:5], 1):\n",
    "            print(f\"\\n{i}. Score: {result.get('score', 0):.4f}\")\n",
    "            print(f\"   Patient: {result.get('patient_id', 'N/A')[:20]}...\")\n",
    "            print(f\"   Note Type: {result.get('note_type', 'N/A')}\")\n",
    "            print(f\"   Note Date: {result.get('note_date', 'N/A')}\")\n",
    "\n",
    "            if result.get('distance') is not None:\n",
    "                print(f\"   Distance: {result['distance']:.4f}\")\n",
    "            if result.get('keyword_score') is not None:\n",
    "                print(f\"   Keyword Score: {result['keyword_score']:.4f}\")\n",
    "\n",
    "            if show_text:\n",
    "                text = result.get('text_chunk') or result.get('text_full', '')\n",
    "                if text:\n",
    "                    snippet = text[:200] + \"...\" if len(text) > 200 else text\n",
    "                    print(f\"   Snippet: {snippet}\")\n",
    "\n",
    "# Display results\n",
    "display_search_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: Adding Date Filters\n\nYou can filter search results by date range using:\n\n- `date-from` - Include notes from this date onwards (YYYY-MM-DD, inclusive)\n- `date-to` - Include notes up to this date (YYYY-MM-DD, inclusive)\n\nThis is useful for:\n- Finding recent documentation for a condition\n- Analyzing notes within a specific time period\n- Tracking progression of a condition over time"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search with date range\n",
    "# Adjust dates based on your indexed data\n",
    "\n",
    "# Calculate date range (last 6 months)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=180)\n",
    "\n",
    "date_from = start_date.strftime(\"%Y-%m-%d\")\n",
    "date_to = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Searching from {date_from} to {date_to}\")\n",
    "\n",
    "# Perform date-filtered search\n",
    "date_results = search(\n",
    "    query=\"diabetes mellitus\",\n",
    "    k=20,\n",
    "    date_from=date_from,\n",
    "    date_to=date_to\n",
    ")\n",
    "\n",
    "print(f\"\\nFound {len(date_results.get('results', []))} results in date range\")\n",
    "display_search_results(date_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare search results across different time periods\n",
    "def search_by_quarters(query: str, year: int = 2025) -> Dict[str, Dict]:\n",
    "    \"\"\"Search by quarter and compare results.\"\"\"\n",
    "    quarters = {\n",
    "        \"Q1\": (f\"{year}-01-01\", f\"{year}-03-31\"),\n",
    "        \"Q2\": (f\"{year}-04-01\", f\"{year}-06-30\"),\n",
    "        \"Q3\": (f\"{year}-07-01\", f\"{year}-09-30\"),\n",
    "        \"Q4\": (f\"{year}-10-01\", f\"{year}-12-31\"),\n",
    "    }\n",
    "\n",
    "    results_by_quarter = {}\n",
    "\n",
    "    for quarter, (start, end) in quarters.items():\n",
    "        print(f\"Searching {quarter} ({start} to {end})...\")\n",
    "        result = search(query, date_from=start, date_to=end, k=50)\n",
    "        results_by_quarter[quarter] = result\n",
    "\n",
    "    return results_by_quarter\n",
    "\n",
    "# Example (uncomment to run):\n",
    "# quarterly_results = search_by_quarters(\"heart failure\", year=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 4: Comparing Search Types\n\nDifferent search types excel at different tasks:\n\n| Search Type | Strengths | Weaknesses |\n|-------------|-----------|------------|\n| **Keyword** | Exact matches, medical codes, specific terminology | Misses synonyms, conceptual matches |\n| **Semantic** | Conceptual similarity, synonyms, paraphrasing | May miss exact term matches |\n| **Hybrid** | Best of both worlds | Slightly more latency |\n\nLet's compare results for the same query across all three modes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_types(query: str, k: int = 10) -> Dict[str, Dict]:\n",
    "    \"\"\"Run the same query across all search types and compare.\"\"\"\n",
    "    search_types = [\"keyword\", \"semantic\", \"hybrid\"]\n",
    "    results = {}\n",
    "\n",
    "    for stype in search_types:\n",
    "        print(f\"Running {stype} search...\")\n",
    "        results[stype] = search(query, search_type=stype, k=k, rerank=(stype == \"hybrid\"))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Compare search types\n",
    "query = \"patient with elevated blood glucose\"\n",
    "comparison = compare_search_types(query, k=20)\n",
    "\n",
    "# Display comparison summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEARCH TYPE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "for stype, result in comparison.items():\n",
    "    meta = result.get(\"metadata\", {})\n",
    "    print(f\"\\n{stype.upper()} Search:\")\n",
    "    print(f\"  Results returned: {meta.get('total_results', 0)}\")\n",
    "    if meta.get('exact_match_count') is not None:\n",
    "        print(f\"  Keyword matches: {meta.get('exact_match_count', 'N/A'):,}\")\n",
    "    if meta.get('semantic_match_count') is not None:\n",
    "        print(f\"  Semantic matches: {meta.get('semantic_match_count', 'N/A'):,}\")\n",
    "    print(f\"  Unique patients: {meta.get('unique_patients', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Visualizing Search Results\n\nThis section provides visualizations to help analyze search results:\n\n1. **Count Metrics** - Unique patients, encounters, notes\n2. **Omission Analysis** - Impact of noise filtering\n3. **Score Distributions** - Relevance score, distance, keyword score\n4. **Search Type Comparison** - Performance across modes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_omitted_results(response: Dict[str, Any]):\n",
    "    \"\"\"Visualize omitted (noise-filtered) results.\"\"\"\n",
    "    metadata = response.get(\"metadata\", {})\n",
    "    omitted = metadata.get(\"omitted_results\")\n",
    "\n",
    "    if not omitted:\n",
    "        print(\"No omission data available (noise filtering may be disabled or skipped)\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Left: Omitted by type\n",
    "    ax1 = axes[0]\n",
    "    omit_types = []\n",
    "    omit_counts = []\n",
    "\n",
    "    if omitted.get(\"semantic_omitted\") is not None:\n",
    "        omit_types.append(\"Semantic\\nOmitted\")\n",
    "        omit_counts.append(omitted[\"semantic_omitted\"])\n",
    "    if omitted.get(\"keyword_omitted\") is not None:\n",
    "        omit_types.append(\"Keyword\\nOmitted\")\n",
    "        omit_counts.append(omitted[\"keyword_omitted\"])\n",
    "\n",
    "    if omit_types:\n",
    "        colors = ['#c0392b', '#d35400']\n",
    "        bars = ax1.bar(omit_types, omit_counts, color=colors, edgecolor='black')\n",
    "        ax1.set_ylabel('Omitted Count')\n",
    "        ax1.set_title('Results Filtered as Noise')\n",
    "\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.annotate(f'{int(height):,}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3), textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "        if omitted.get(\"is_minimum\"):\n",
    "            ax1.annotate(\"* Counts are minimum estimates\",\n",
    "                        xy=(0.5, 0.02), xycoords='axes fraction',\n",
    "                        fontsize=9, fontstyle='italic', ha='center')\n",
    "\n",
    "    # Right: Included vs Omitted pie chart\n",
    "    ax2 = axes[1]\n",
    "    total_results = metadata.get(\"total_results\", 0)\n",
    "    total_omitted = omitted.get(\"total_omitted\", 0)\n",
    "\n",
    "    if total_results > 0 or total_omitted > 0:\n",
    "        sizes = [total_results, total_omitted]\n",
    "        labels = [f'Included\\n({total_results:,})', f'Omitted\\n({total_omitted:,})']\n",
    "        colors = ['#27ae60', '#e74c3c']\n",
    "        explode = (0, 0.05)\n",
    "\n",
    "        ax2.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "               autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "        ax2.set_title('Results Distribution')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No data to display',\n",
    "                ha='center', va='center', fontsize=12, transform=ax2.transAxes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize omission data\n",
    "if results.get(\"results\"):\n",
    "    visualize_omitted_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ranking_metrics(response: Dict[str, Any]):\n",
    "    \"\"\"Visualize ranking metrics (vector_rank, bm25_rank) when available.\"\"\"\n",
    "    results = response.get(\"results\", [])\n",
    "    metadata = response.get(\"metadata\", {})\n",
    "\n",
    "    # Check if fusion details are available (requires rerank=false)\n",
    "    if metadata.get(\"reranked\", True):\n",
    "        print(\"Ranking details are only available when rerank=false\")\n",
    "        print(\"Run: search(query, rerank=False)\")\n",
    "        return\n",
    "\n",
    "    # Extract ranking data\n",
    "    ranking_data = []\n",
    "    for i, r in enumerate(results):\n",
    "        if r.get(\"vector_rank\") is not None or r.get(\"bm25_rank\") is not None:\n",
    "            ranking_data.append({\n",
    "                \"result_position\": i + 1,\n",
    "                \"vector_rank\": r.get(\"vector_rank\"),\n",
    "                \"bm25_rank\": r.get(\"bm25_rank\"),\n",
    "                \"fusion_score\": r.get(\"fusion_score\", 0)\n",
    "            })\n",
    "\n",
    "    if not ranking_data:\n",
    "        print(\"No ranking data available in results\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(ranking_data)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Left: Vector vs BM25 rank scatter\n",
    "    ax1 = axes[0]\n",
    "    scatter = ax1.scatter(\n",
    "        df[\"vector_rank\"].fillna(df[\"vector_rank\"].max() + 10),\n",
    "        df[\"bm25_rank\"].fillna(df[\"bm25_rank\"].max() + 10),\n",
    "        c=df[\"fusion_score\"],\n",
    "        cmap='viridis',\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolor='black'\n",
    "    )\n",
    "    ax1.set_xlabel('Vector Rank')\n",
    "    ax1.set_ylabel('BM25 Rank')\n",
    "    ax1.set_title('Vector vs BM25 Ranking')\n",
    "    plt.colorbar(scatter, ax=ax1, label='Fusion Score')\n",
    "\n",
    "    # Right: Rank contribution to final position\n",
    "    ax2 = axes[1]\n",
    "    positions = df[\"result_position\"]\n",
    "    ax2.plot(positions, df[\"vector_rank\"], 'o-', label='Vector Rank', color='teal')\n",
    "    ax2.plot(positions, df[\"bm25_rank\"], 's-', label='BM25 Rank', color='coral')\n",
    "    ax2.set_xlabel('Final Result Position')\n",
    "    ax2.set_ylabel('Original Rank')\n",
    "    ax2.set_title('Rank Contribution to Final Position')\n",
    "    ax2.legend()\n",
    "    ax2.invert_yaxis()  # Lower rank = better\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run a search without reranking to see fusion details\n",
    "unranked_results = search(\"diabetes\", k=15, rerank=False)\n",
    "visualize_ranking_metrics(unranked_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nIn this notebook, you learned how to:\n\n1. **Configure Authentication** - Set up your API key for secure access\n2. **Discover Cohorts** - List indexed cohorts available for search\n3. **Search Notes** - Use keyword, semantic, and hybrid search modes\n4. **Apply Filters** - Filter by date range, note type, and other criteria\n5. **Visualize Results** - Analyze search results with charts and metrics\n\n## Key API Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/health` | GET | Health check |\n| `/cohorts/indexed` | GET | List indexed cohorts |\n| `/search` | GET | Search notes |\n\n## Next Steps\n\n- Explore the Search API documentation\n- Check out the advanced filtering options (noise detection, note types)\n- Experiment with different search types and parameters\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Connection refused** - Contact your administrator to verify the API endpoints\n\n2. **401 Unauthorized** - Check your API key is valid and has correct entitlements\n\n3. **No cohorts found** - Data may not be indexed yet or your API key may not have access\n\n4. **Slow searches** - Try reducing `k` or disabling `rerank` for faster results"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}