{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Getting Started with Trioexplorer API\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/triohealth/trioexplorer/blob/main/notebooks/getting_started.ipynb)\n\nThis notebook demonstrates how to use the Trioexplorer API to search clinical notes across patient cohorts. You will learn a **broad-to-narrow** search workflow:\n\n1. Start with a broad search to see what's available\n2. Apply quality filters to reduce noise\n3. Add date filters to focus on specific time periods\n4. Use entity filters for clinical precision\n5. Review results grouped by encounter\n\n## Prerequisites\n\n**You will need:**\n- An API key for the Trioexplorer API\n- Contact your administrator to obtain an API key"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install -q requests pandas matplotlib seaborn numpy\n\n# Import dependencies\nimport requests\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, Any, List\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure matplotlib for notebook display\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\nprint(\"✓ All dependencies loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION - Modify these values for your use case\n# =============================================================================\n\n# Search Configuration\nSEARCH_TERM = \"side effects\"  # Change this to your search query\nCOHORT_IDS = None             # Set to a list of cohort IDs, e.g., [\"cohort-1\", \"cohort-2\"], or None for all\nTOP_K = 10000                 # Number of results to retrieve (max 10,000)\n\n# API Configuration\nTRIO_API_URL = \"https://search.trioexplorer.com\"\n\nprint(f\"Search API: {TRIO_API_URL}\")\nprint(f\"Search Term: '{SEARCH_TERM}'\")\nprint(f\"Cohort Filter: {COHORT_IDS if COHORT_IDS else 'All cohorts'}\")\nprint(f\"Top K: {TOP_K:,}\")"
  },
  {
   "cell_type": "code",
   "id": "h5s82t63w4c",
   "source": "# API Key Configuration\n# Option 1 (Recommended): Use Colab secrets\ntry:\n    from google.colab import userdata\n    TRIO_API_KEY = userdata.get('TRIO_API_KEY')\n    print(\"✓ API key loaded from Colab secrets\")\nexcept:\n    # Option 2: Set directly (not recommended for shared notebooks)\n    TRIO_API_KEY = os.environ.get(\"TRIO_API_KEY\", \"\")\n    if not TRIO_API_KEY:\n        print(\"⚠️  WARNING: No API key configured!\")\n        print(\"Add TRIO_API_KEY to Colab secrets, or set it manually:\")\n        print('TRIO_API_KEY = \"your_api_key_here\"')\n    else:\n        print(f\"✓ API Key configured: {TRIO_API_KEY[:8]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2l9curo7fse",
   "source": "# =============================================================================\n# VALIDATION - Verify API connectivity before proceeding\n# =============================================================================\n\ndef validate_api_connection():\n    \"\"\"Validate API key and connectivity.\"\"\"\n    print(\"Validating API connection...\\n\")\n    \n    # Check API health\n    try:\n        health_response = requests.get(f\"{TRIO_API_URL}/health\", timeout=5)\n        if health_response.status_code == 200:\n            print(\"✓ API server is reachable\")\n        else:\n            print(f\"✗ API server returned status {health_response.status_code}\")\n            return False\n    except requests.exceptions.ConnectionError:\n        print(f\"✗ Cannot connect to API at {TRIO_API_URL}\")\n        return False\n    except Exception as e:\n        print(f\"✗ Connection error: {str(e)}\")\n        return False\n    \n    # Test API key by fetching cohorts\n    if not TRIO_API_KEY:\n        print(\"✗ No API key configured\")\n        return False\n    \n    try:\n        test_response = requests.get(\n            f\"{TRIO_API_URL}/cohorts/indexed\",\n            headers={\"X-API-Key\": TRIO_API_KEY},\n            params={\"limit\": 1},\n            timeout=10\n        )\n        if test_response.status_code == 200:\n            print(\"✓ API key is valid\")\n            return True\n        elif test_response.status_code == 401:\n            print(\"✗ API key is invalid or expired\")\n            return False\n        elif test_response.status_code == 403:\n            print(\"✗ API key does not have access to this resource\")\n            return False\n        else:\n            print(f\"✗ Unexpected response: {test_response.status_code}\")\n            return False\n    except Exception as e:\n        print(f\"✗ Error testing API key: {str(e)}\")\n        return False\n\nis_valid = validate_api_connection()\n\nif is_valid:\n    print(\"\\n\" + \"=\" * 50)\n    print(\"✓ Ready to proceed!\")\n    print(\"=\" * 50)\nelse:\n    print(\"\\n\" + \"=\" * 50)\n    print(\"✗ Please fix the issues above before continuing\")\n    print(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Discover Available Cohorts\n\nBefore searching, you need to know which cohorts are indexed and available. The `/cohorts/indexed` endpoint lists all cohorts with searchable data.\n\nEach indexed cohort includes:\n- `cohort_id` - Unique identifier\n- `cohort_name` - Human-readable name (if available)\n- `namespace` - The index partition for this cohort in our search system\n- `chunk_count` - Number of indexed chunks (vectors)\n- `index_status` - Current indexing status"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_indexed_cohorts(limit: int = 20) -> List[Dict[str, Any]]:\n    \"\"\"\n    List all indexed cohorts available for search.\n\n    Args:\n        limit: Maximum number of cohorts to return (max 100)\n\n    Returns:\n        List of indexed cohort information\n    \"\"\"\n    response = requests.get(\n        f\"{TRIO_API_URL}/cohorts/indexed\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params={\"limit\": limit}\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        cohorts = data.get(\"items\", [])\n        total = data.get(\"total_count\", len(cohorts))\n        print(f\"Found {total} indexed cohorts (showing {len(cohorts)})\")\n        return cohorts\n    else:\n        print(f\"Failed to list cohorts: {response.status_code}\")\n        print(response.text)\n        return []\n\n# Fetch indexed cohorts\ncohorts = get_indexed_cohorts()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display cohorts as a formatted table\nif cohorts:\n    cohorts_df = pd.DataFrame(cohorts)\n\n    # Format the display\n    display_cols = [\"cohort_id\", \"cohort_name\", \"chunk_count\", \"index_status\"]\n    available_cols = [c for c in display_cols if c in cohorts_df.columns]\n\n    print(\"\\nIndexed Cohorts:\")\n    print(\"-\" * 80)\n    display(cohorts_df[available_cols].style.format({\n        \"chunk_count\": \"{:,}\"\n    }))\n\n    # Summary statistics\n    total_chunks = cohorts_df[\"chunk_count\"].sum()\n    print(f\"\\nTotal indexed chunks across all cohorts: {total_chunks:,}\")\nelse:\n    print(\"No cohorts available. Ensure data has been indexed.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Broad Search\n\nNow let's perform a broad search using your configured `SEARCH_TERM`. We'll start with a high `k` value (10,000) to see the full scope of matching results.\n\nThe Search API supports three search modes:\n\n| Mode | Description | Best For |\n|------|-------------|----------|\n| `keyword` | BM25 full-text search | Exact terms, medical codes |\n| `semantic` | Vector similarity search | Conceptual queries |\n| `hybrid` (default) | Combines both approaches | General-purpose queries |\n\n**Goal:** Get a broad view of results, then narrow down with filters in subsequent steps."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def search(\n    query: str,\n    search_type: str = \"hybrid\",\n    k: int = 10,\n    cohort_ids: Optional[List[str]] = None,\n    rerank: bool = True,\n    date_from: Optional[str] = None,\n    date_to: Optional[str] = None,\n    note_types: Optional[List[str]] = None,\n    include_noise: bool = False,\n    distinct: Optional[str] = None,\n    vector_weight: Optional[float] = None,\n    top_k_retrieval: Optional[int] = None,\n    distance_threshold: Optional[float] = None,\n    chunk_multiplier: Optional[int] = None,\n    min_quality_score: Optional[float] = None,\n    min_chunk_quality_score: Optional[float] = None,\n    filters: Optional[Dict[str, Any]] = None,\n    entity_filters: Optional[Dict[str, Any]] = None,\n    **kwargs\n) -> Dict[str, Any]:\n    \"\"\"\n    Search indexed patient notes.\n\n    Args:\n        query: Search text\n        search_type: 'keyword', 'semantic', or 'hybrid' (default)\n        k: Number of results to return (max 10,000)\n        cohort_ids: List of cohort IDs to search\n        rerank: Apply Cohere reranking (default True)\n        date_from: Filter from date (YYYY-MM-DD)\n        date_to: Filter to date (YYYY-MM-DD)\n        note_types: Filter by note types\n        include_noise: Include noise notes (default False)\n        distinct: De-duplication mode ('encounter', 'patient', 'note', or 'none')\n        vector_weight: Weight for vector search in fusion (0.0-1.0)\n        top_k_retrieval: Number of results to retrieve before reranking\n        distance_threshold: Cosine distance cutoff for semantic results\n        chunk_multiplier: Initial retrieval multiplier for semantic search\n        min_quality_score: Minimum note quality score (0.0-1.0)\n        min_chunk_quality_score: Minimum chunk quality score (0.0-1.0)\n        filters: Attribute filters as dict (converted to JSON)\n        entity_filters: Entity/assertion filters as dict (converted to JSON)\n\n    Returns:\n        Search response with results and metadata\n    \"\"\"\n    params = {\n        \"query\": query,\n        \"search-type\": search_type,\n        \"k\": k,\n        \"rerank\": str(rerank).lower(),\n        \"include-noise\": str(include_noise).lower(),\n    }\n\n    if cohort_ids:\n        params[\"cohort-ids\"] = \",\".join(str(c) for c in cohort_ids)\n    if date_from:\n        params[\"date-from\"] = date_from\n    if date_to:\n        params[\"date-to\"] = date_to\n    if note_types:\n        params[\"note-types\"] = \",\".join(note_types)\n    if distinct:\n        params[\"distinct\"] = distinct\n    if vector_weight is not None:\n        params[\"vector-weight\"] = vector_weight\n    if top_k_retrieval is not None:\n        params[\"top-k-retrieval\"] = top_k_retrieval\n    if distance_threshold is not None:\n        params[\"distance-threshold\"] = distance_threshold\n    if chunk_multiplier is not None:\n        params[\"chunk-multiplier\"] = chunk_multiplier\n    if min_quality_score is not None:\n        params[\"min-quality-score\"] = min_quality_score\n    if min_chunk_quality_score is not None:\n        params[\"min-chunk-quality-score\"] = min_chunk_quality_score\n    if filters:\n        params[\"filters\"] = json.dumps(filters)\n    if entity_filters:\n        params[\"entity-filters\"] = json.dumps(entity_filters)\n\n    for key, value in kwargs.items():\n        params[key.replace(\"_\", \"-\")] = value\n\n    response = requests.get(\n        f\"{TRIO_API_URL}/search\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params=params\n    )\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Search failed: {response.status_code}\")\n        print(response.text)\n        return {\"results\": [], \"metadata\": {}}\n\n# Perform broad search with configured SEARCH_TERM\nprint(f\"Searching for: '{SEARCH_TERM}'\")\nprint(f\"Cohorts: {COHORT_IDS if COHORT_IDS else 'All'}\")\nprint(\"-\" * 50)\n\nbroad_results = search(\n    query=SEARCH_TERM,\n    k=TOP_K,\n    cohort_ids=COHORT_IDS\n)\n\n# Store result count for funnel tracking\nbroad_count = broad_results.get(\"metadata\", {}).get(\"total_results\", len(broad_results.get(\"results\", [])))\nprint(f\"\\n✓ Broad search returned {broad_count} results\")\nprint(f\"  Unique patients: {broad_results.get('metadata', {}).get('unique_patients', 'N/A')}\")\nprint(f\"  Unique encounters: {broad_results.get('metadata', {}).get('unique_encounters', 'N/A')}\")\n\n# Initialize funnel tracking\nfilter_funnel = {\"Broad Search\": broad_count}"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Step 3: Filtering by Quality Score\n\nQuality scores help filter out low-quality or noisy clinical text. This is often the most impactful filter for improving result relevance.\n\n**Key Parameters:**\n- `min_quality_score` - Minimum note-level quality (0.0-1.0)\n- `min_chunk_quality_score` - Minimum chunk-level quality (0.0-1.0)\n\nHigher scores mean cleaner, more clinically relevant text. A threshold of **0.7** typically removes most noise while preserving valuable content."
  },
  {
   "cell_type": "code",
   "id": "0utxearg5p7",
   "source": "# Apply quality score filters\nquality_results = search(\n    query=SEARCH_TERM,\n    k=TOP_K,\n    cohort_ids=COHORT_IDS,\n    min_quality_score=0.7,\n    min_chunk_quality_score=0.6\n)\n\nquality_count = quality_results.get(\"metadata\", {}).get(\"total_results\", len(quality_results.get(\"results\", [])))\nfilter_funnel[\"+ Quality ≥0.7\"] = quality_count\n\nprint(f\"Results with quality filters:\")\nprint(f\"  Before: {broad_count}\")\nprint(f\"  After:  {quality_count}\")\nprint(f\"  Reduction: {broad_count - quality_count} results filtered ({(1 - quality_count/max(broad_count,1))*100:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6khuk3gg379",
   "source": "## Step 4: Adding Date Filters\n\nYou can filter search results by date range using:\n\n- `date-from` - Include notes from this date onwards (YYYY-MM-DD, inclusive)\n- `date-to` - Include notes up to this date (YYYY-MM-DD, inclusive)\n\nThis is useful for:\n- Finding recent documentation for a condition\n- Analyzing notes within a specific time period\n- Tracking progression of a condition over time",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7t3rt866j9a",
   "source": "# Add date filters to further narrow results\n# Using last 6 months as an example - adjust based on your data\n\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=180)\n\ndate_from = start_date.strftime(\"%Y-%m-%d\")\ndate_to = end_date.strftime(\"%Y-%m-%d\")\n\nprint(f\"Adding date filter: {date_from} to {date_to}\")\n\ndate_results = search(\n    query=SEARCH_TERM,\n    k=TOP_K,\n    cohort_ids=COHORT_IDS,\n    min_quality_score=0.7,\n    min_chunk_quality_score=0.6,\n    date_from=date_from,\n    date_to=date_to\n)\n\ndate_count = date_results.get(\"metadata\", {}).get(\"total_results\", len(date_results.get(\"results\", [])))\nfilter_funnel[\"+ Date Filter\"] = date_count\n\nprint(f\"\\nResults with date filter added:\")\nprint(f\"  Before: {quality_count}\")\nprint(f\"  After:  {date_count}\")\nprint(f\"  Reduction: {quality_count - date_count} results filtered\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dyntf8k8zv",
   "source": "# Timeline visualization: Show results distribution over time\nresults_list = date_results.get(\"results\", [])\n\nif results_list:\n    # Extract dates from results\n    dates = []\n    for r in results_list:\n        note_date = r.get(\"note_date\")\n        if note_date:\n            try:\n                dates.append(pd.to_datetime(note_date))\n            except:\n                pass\n    \n    if dates:\n        fig, ax = plt.subplots(figsize=(12, 4))\n        \n        # Create histogram of results by month\n        date_series = pd.Series(dates)\n        date_series.groupby(date_series.dt.to_period(\"M\")).count().plot(\n            kind=\"bar\", ax=ax, color=\"#3498db\", edgecolor=\"black\"\n        )\n        \n        ax.set_xlabel(\"Month\")\n        ax.set_ylabel(\"Number of Results\")\n        ax.set_title(f\"Results Timeline for '{SEARCH_TERM}'\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"No dates available in results for timeline visualization\")\nelse:\n    print(\"No results to visualize\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "selb43ox9x",
   "source": "## Step 5: Entity and Assertion Filtering\n\nThe Search API can filter results based on extracted clinical entities and their assertion status. This is powerful for finding specific clinical mentions with context.\n\n### Entity Types\n\nClinical entities are extracted and categorized into these types:\n\n| Entity Type | Description | Examples |\n|-------------|-------------|----------|\n| `symptoms` | Patient-reported or observed symptoms | \"chest pain\", \"shortness of breath\" |\n| `diagnoses` | Medical diagnoses and conditions | \"diabetes mellitus\", \"hypertension\" |\n| `medications` | Drugs and medications | \"metformin\", \"lisinopril\" |\n| `procedures` | Medical procedures | \"colonoscopy\", \"cardiac catheterization\" |\n| `lab_tests` | Laboratory tests | \"HbA1c\", \"CBC\" |\n| `vital_signs` | Vital sign measurements | \"blood pressure\", \"heart rate\" |\n\n### Assertion Types\n\nEach entity has an assertion status indicating clinical context:\n\n| Assertion Type | Description | Example Context |\n|----------------|-------------|-----------------|\n| `present` | Currently present/active | \"Patient has diabetes\" |\n| `negated` | Explicitly negated | \"No chest pain\" |\n| `historical` | Past history | \"History of MI in 2019\" |\n| `family` | Family history | \"Mother had breast cancer\" |\n| `hypothetical` | Possible/uncertain | \"Rule out PE\" |\n| `conditional` | Conditional mention | \"If symptoms worsen\" |\n\n### Combining Entity and Assertion Types\n\nFilter keys combine entity type and assertion type with an underscore: `{entity_type}_{assertion_type}`\n\n**Examples:**\n- `symptoms_present` - Active symptoms\n- `diagnoses_negated` - Ruled-out diagnoses\n- `medications_historical` - Previously prescribed medications\n- `diagnoses_family` - Family history of conditions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jao7xqbcwm",
   "source": "# Apply entity filters for clinical precision\n# Example: Filter for notes with present symptoms related to our search\n\nentity_results = search(\n    query=SEARCH_TERM,\n    k=TOP_K,\n    cohort_ids=COHORT_IDS,\n    min_quality_score=0.7,\n    min_chunk_quality_score=0.6,\n    date_from=date_from,\n    date_to=date_to,\n    entity_filters={\n        \"symptoms_present\": [\"nausea\", \"fatigue\", \"headache\"]  # Adjust based on your search term\n    }\n)\n\nentity_count = entity_results.get(\"metadata\", {}).get(\"total_results\", len(entity_results.get(\"results\", [])))\nfilter_funnel[\"+ Entity Filter\"] = entity_count\n\nprint(f\"Results with entity filter added:\")\nprint(f\"  Before: {date_count}\")\nprint(f\"  After:  {entity_count}\")\nprint(f\"  Reduction: {date_count - entity_count} results filtered\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "kuzgrwkg86",
   "source": "# Funnel Chart: Visualize the broad-to-narrow workflow\nfig, ax = plt.subplots(figsize=(10, 6))\n\nsteps = list(filter_funnel.keys())\ncounts = list(filter_funnel.values())\n\n# Create horizontal bar chart (funnel style)\ncolors = plt.cm.Blues(np.linspace(0.3, 0.9, len(steps)))[::-1]\nbars = ax.barh(range(len(steps)), counts, color=colors, edgecolor='black')\n\n# Add count labels\nfor i, (bar, count) in enumerate(zip(bars, counts)):\n    ax.text(bar.get_width() + max(counts)*0.02, bar.get_y() + bar.get_height()/2, \n            f'{count:,}', va='center', fontsize=11, fontweight='bold')\n\nax.set_yticks(range(len(steps)))\nax.set_yticklabels(steps)\nax.invert_yaxis()  # Top to bottom\nax.set_xlabel('Number of Results')\nax.set_title(f\"Filter Funnel: '{SEARCH_TERM}'\", fontsize=14, fontweight='bold')\nax.set_xlim(0, max(counts) * 1.15)\n\nplt.tight_layout()\nplt.show()\n\n# Print summary\nprint(\"\\n\" + \"=\" * 50)\nprint(\"FILTER FUNNEL SUMMARY\")\nprint(\"=\" * 50)\nfor step, count in filter_funnel.items():\n    print(f\"  {step}: {count:,} results\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "gasckmj3chh",
   "source": "## Step 6: Advanced Filters\n\nFor complex filtering scenarios, you can pass raw filter expressions. These filters operate directly on indexed attributes and support various operators.\n\n### Filter Syntax\n\nFilters are passed as JSON objects with the following structure:\n\n```json\n{\n    \"field_name\": [\"value1\", \"value2\"],       // In list (OR)\n    \"field_name\": {\"$eq\": \"exact_value\"},     // Exact match\n    \"field_name\": {\"$ne\": \"excluded_value\"},  // Not equal\n    \"field_name\": {\"$in\": [\"a\", \"b\", \"c\"]},   // In list\n    \"field_name\": {\"$nin\": [\"x\", \"y\"]},       // Not in list\n    \"field_name\": {\"$gt\": 0.5},               // Greater than\n    \"field_name\": {\"$gte\": 0.5},              // Greater than or equal\n    \"field_name\": {\"$lt\": 1.0},               // Less than\n    \"field_name\": {\"$lte\": 1.0}               // Less than or equal\n}\n```\n\n### Common Filterable Fields\n\n- `note_type` - Type of clinical note\n- `quality_score` - Note quality score (0.0-1.0)\n- `chunk_quality_score` - Chunk quality score (0.0-1.0)\n- `patient_id` - Patient identifier\n- `encounter_id` - Encounter identifier",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ff0b8mh8m39",
   "source": "# Example: Using raw filters for specific note types\n# Filter to only include \"Progress Notes\" and \"Discharge Summary\"\n\nfiltered_results = search(\n    query=SEARCH_TERM,\n    k=TOP_K,\n    cohort_ids=COHORT_IDS,\n    filters={\n        \"note_type\": [\"Progress Note\", \"Discharge Summary\"]\n    }\n)\n\nprint(f\"Results filtered by note type:\")\nprint(f\"  Found {len(filtered_results.get('results', []))} results\")\n\n# Show note type distribution in results\nif filtered_results.get(\"results\"):\n    note_types = [r.get(\"note_type\", \"Unknown\") for r in filtered_results[\"results\"]]\n    type_counts = pd.Series(note_types).value_counts()\n    print(\"\\nNote type distribution:\")\n    for nt, count in type_counts.items():\n        print(f\"  {nt}: {count}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "o2djtjhqio",
   "source": "## Step 7: Filter Field Discovery\n\nBefore building complex filters, you can discover what filter fields are available and their possible values. \n\nEach cohort has a `namespace` - this is the index partitioning scheme in our search system that organizes the data for efficient retrieval.\n\n### Endpoints\n\n- `GET /namespaces/{namespace}/filter-fields` - List available filter fields\n- `GET /namespaces/{namespace}/filter-values/{field}` - Get values for a specific field",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3o0fdbwl48y",
   "source": "def get_filter_fields(\n    namespace: str,\n    category: Optional[str] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    List available filter fields for a namespace.\n\n    Args:\n        namespace: The namespace from cohort info (index partition identifier)\n        category: Filter by category (e.g., 'metadata', 'entity')\n\n    Returns:\n        List of filter field definitions\n    \"\"\"\n    params = {}\n    if category:\n        params[\"category\"] = category\n\n    response = requests.get(\n        f\"{TRIO_API_URL}/namespaces/{namespace}/filter-fields\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params=params\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        fields = data.get(\"fields\", [])\n        print(f\"Found {len(fields)} filter fields for namespace '{namespace}'\")\n        return fields\n    else:\n        print(f\"Failed to get filter fields: {response.status_code}\")\n        print(response.text)\n        return []\n\n\ndef get_filter_values(\n    namespace: str,\n    field: str,\n    limit: int = 50\n) -> List[Any]:\n    \"\"\"\n    Get possible values for a filter field.\n\n    Args:\n        namespace: The namespace (index partition identifier)\n        field: Field name to get values for\n        limit: Maximum number of values to return\n\n    Returns:\n        List of possible values for the field\n    \"\"\"\n    response = requests.get(\n        f\"{TRIO_API_URL}/namespaces/{namespace}/filter-values/{field}\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params={\"limit\": limit}\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        values = data.get(\"values\", [])\n        total = data.get(\"total_count\", len(values))\n        print(f\"Found {total} values for field '{field}' (showing {len(values)})\")\n        return values\n    else:\n        print(f\"Failed to get filter values: {response.status_code}\")\n        print(response.text)\n        return []",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yk455sk53y",
   "source": "# Example: Discover filter fields for a cohort\n# First, get a namespace from an indexed cohort\n\nif cohorts:\n    # Use the first cohort's namespace\n    example_namespace = cohorts[0].get(\"namespace\")\n    \n    if example_namespace:\n        print(f\"Exploring filter fields for namespace: {example_namespace}\\n\")\n        \n        # Get all available filter fields\n        fields = get_filter_fields(example_namespace)\n        \n        if fields:\n            fields_df = pd.DataFrame(fields)\n            print(\"\\nAvailable Filter Fields:\")\n            print(\"-\" * 60)\n            display(fields_df)\n    else:\n        print(\"No namespace found in cohort data\")\nelse:\n    print(\"No cohorts available. Run the cohorts cell first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "foqovk6liov",
   "source": "# Example: Get possible values for a specific filter field\n# This is useful for building filter dropdowns in UIs\n\nif cohorts:\n    example_namespace = cohorts[0].get(\"namespace\")\n    \n    if example_namespace:\n        # Get values for note_type field\n        print(\"Getting values for 'note_type' field...\\n\")\n        note_type_values = get_filter_values(example_namespace, \"note_type\", limit=20)\n        \n        if note_type_values:\n            print(\"\\nAvailable note_type values:\")\n            for i, value in enumerate(note_type_values, 1):\n                print(f\"  {i}. {value}\")\nelse:\n    print(\"No cohorts available. Run the cohorts cell first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "nzs87129n8",
   "source": "## Step 8: Reviewing Results by Encounter\n\nAfter narrowing down results with filters, the final step is to review the actual clinical notes. Grouping results by encounter helps you understand the context of each finding.\n\nThis section shows how to:\n1. Group results by `encounter_id`\n2. Display an encounter summary table\n3. View actual note text for selected encounters",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "l8aos42jug",
   "source": "# Use the final filtered results (or entity_results if available)\nfinal_results = entity_results if entity_results.get(\"results\") else date_results\n\nresults_list = final_results.get(\"results\", [])\n\nif results_list:\n    # Group results by encounter_id\n    encounters = {}\n    for r in results_list:\n        enc_id = r.get(\"encounter_id\", \"Unknown\")\n        if enc_id not in encounters:\n            encounters[enc_id] = {\n                \"patient_id\": r.get(\"patient_id\", \"Unknown\"),\n                \"notes\": [],\n                \"dates\": [],\n                \"note_types\": set()\n            }\n        encounters[enc_id][\"notes\"].append(r)\n        if r.get(\"note_date\"):\n            encounters[enc_id][\"dates\"].append(r.get(\"note_date\"))\n        if r.get(\"note_type\"):\n            encounters[enc_id][\"note_types\"].add(r.get(\"note_type\"))\n    \n    # Create encounter summary table\n    summary_data = []\n    for enc_id, data in encounters.items():\n        dates = sorted(data[\"dates\"]) if data[\"dates\"] else []\n        summary_data.append({\n            \"encounter_id\": enc_id[:20] + \"...\" if len(str(enc_id)) > 20 else enc_id,\n            \"patient_id\": data[\"patient_id\"][:15] + \"...\" if len(str(data[\"patient_id\"])) > 15 else data[\"patient_id\"],\n            \"note_count\": len(data[\"notes\"]),\n            \"note_types\": \", \".join(sorted(data[\"note_types\"]))[:40],\n            \"date_range\": f\"{dates[0]} to {dates[-1]}\" if len(dates) > 1 else (dates[0] if dates else \"N/A\")\n        })\n    \n    summary_df = pd.DataFrame(summary_data)\n    summary_df = summary_df.sort_values(\"note_count\", ascending=False).head(10)\n    \n    print(f\"Found {len(encounters)} unique encounters\")\n    print(\"\\nTop 10 Encounters by Note Count:\")\n    print(\"-\" * 80)\n    display(summary_df)\nelse:\n    print(\"No results available. Run the search cells above first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1wa8ya441jk",
   "source": "# Display actual note text for the first few encounters\nif results_list and encounters:\n    print(\"=\" * 80)\n    print(\"SAMPLE NOTE TEXT\")\n    print(\"=\" * 80)\n    \n    # Get first 3 encounters with notes\n    sample_encounters = list(encounters.items())[:3]\n    \n    for enc_id, data in sample_encounters:\n        print(f\"\\n{'─' * 80}\")\n        print(f\"ENCOUNTER: {enc_id}\")\n        print(f\"Patient: {data['patient_id']}\")\n        print(f\"Notes: {len(data['notes'])}\")\n        print(f\"{'─' * 80}\")\n        \n        # Show first note from this encounter\n        note = data[\"notes\"][0]\n        print(f\"\\nNote Type: {note.get('note_type', 'N/A')}\")\n        print(f\"Note Date: {note.get('note_date', 'N/A')}\")\n        print(f\"Score: {note.get('score', 0):.4f}\")\n        \n        # Display text snippet\n        text = note.get('text_chunk') or note.get('text_full', '')\n        if text:\n            print(f\"\\nText Preview:\")\n            print(\"-\" * 40)\n            # Show first 500 characters\n            preview = text[:500] + \"...\" if len(text) > 500 else text\n            print(preview)\n        else:\n            print(\"\\n(No text available in result)\")\nelse:\n    print(\"No encounters to display\")",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Summary\n\nThis notebook demonstrated a **broad-to-narrow** search workflow:\n\n```\nBroad search (k=10000)   ████████████████████  → Start with all matches\n+ quality ≥0.7           ████████████          → Remove noisy content\n+ date filter            ██████                → Focus on time period\n+ entity filter          ███                   → Clinical precision\n→ Review by encounter    [actual notes]        → Examine results\n```\n\n### What You Learned\n\n1. **Configure & Validate** - Set up API key and verify connectivity\n2. **Discover Cohorts** - Find indexed cohorts available for search\n3. **Broad Search** - Start with high `k` to see the full scope of results\n4. **Quality Filtering** - Use `min_quality_score` to reduce noise\n5. **Date Filtering** - Narrow by time period with `date_from`/`date_to`\n6. **Entity Filtering** - Filter by clinical entities and assertions\n7. **Advanced Filters** - Use raw filter expressions for complex queries\n8. **Filter Discovery** - Explore available fields and values\n9. **Review by Encounter** - Group and examine actual note text\n\n### Key API Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/health` | GET | Health check |\n| `/cohorts/indexed` | GET | List indexed cohorts |\n| `/search` | GET | Search notes with filters |\n| `/namespaces/{ns}/filter-fields` | GET | List filter fields |\n| `/namespaces/{ns}/filter-values/{field}` | GET | Get field values |\n\n### Search Parameters Quick Reference\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string | Search text (required) |\n| `search-type` | string | `keyword`, `semantic`, or `hybrid` |\n| `k` | int | Number of results (max 10,000) |\n| `cohort-ids` | string | Comma-separated cohort IDs |\n| `min-quality-score` | float | Minimum note quality (0.0-1.0) |\n| `date-from` / `date-to` | string | Date range filter (YYYY-MM-DD) |\n| `entity-filters` | JSON | Entity/assertion type filters |\n| `filters` | JSON | Advanced attribute filters |\n\n### Next Steps\n\n- Try different `SEARCH_TERM` values in the configuration cell\n- Adjust entity filters based on your clinical domain\n- Explore the CLI tool: `trioexplorer --help`\n- Build custom filters using the filter discovery endpoints\n\n### Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| Connection refused | Verify API endpoints with your administrator |\n| 401 Unauthorized | Check API key is valid |\n| No cohorts found | Data may not be indexed yet |\n| Too many results | Increase quality score thresholds |\n| No results | Broaden search term or reduce filters |"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}