{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Getting Started with Trioexplorer API\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/triohealth/trioexplorer/blob/main/notebooks/getting_started.ipynb)\n\nThis notebook demonstrates how to use the Trioexplorer API to search clinical notes across patient cohorts. You will learn how to:\n\n1. Configure API authentication\n2. Discover available indexed cohorts and note types\n3. Perform different types of searches (keyword, semantic, hybrid)\n4. Apply date, entity, and advanced filters to search queries\n5. Discover available filter fields and their values\n6. Visualize search results and performance metrics\n\n## Prerequisites\n\n**You will need:**\n- An API key with `read:global` or cohort-specific `read:<cohort-id>` entitlements\n- Contact your administrator to obtain an API key"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install -q requests pandas matplotlib seaborn\n\n# Import dependencies\nimport requests\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, Any, List\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure matplotlib for notebook display\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\nprint(\"✓ All dependencies loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\n\n# Production API Endpoints\n# TODO: Update these URLs with your production endpoints\nTRIO_API_URL = \"http://k8s-notesear-notesear-20ee5f12c9-4c4972a75575c8a7.elb.us-east-1.amazonaws.com:8001\"\n\nprint(f\"Search API: {TRIO_API_URL}\")\n\n# API Key Configuration\n# Option 1 (Recommended): Use Colab secrets\ntry:\n    from google.colab import userdata\n    TRIO_API_KEY = userdata.get('TRIO_API_KEY')\n    print(\"✓ API key loaded from Colab secrets\")\nexcept:\n    # Option 2: Set directly (not recommended - use Colab secrets instead)\n    TRIO_API_KEY = os.environ.get(\"TRIO_API_KEY\", \"\")\n    if not TRIO_API_KEY:\n        print(\"⚠️  WARNING: No API key configured!\")\n        print(\"Add TRIO_API_KEY to Colab secrets, or set it manually:\")\n        print(\"TRIO_API_KEY = 'ts_your_api_key_here'\")\n    else:\n        print(f\"✓ API Key configured: {TRIO_API_KEY[:8]}...\")\n\n# Test connectivity\ndef check_service_health(url: str, name: str) -> bool:\n    \"\"\"Check if the API service is healthy and reachable.\"\"\"\n    try:\n        response = requests.get(f\"{url}/health\", timeout=5)\n        if response.status_code == 200:\n            print(f\"✓ {name} is healthy\")\n            return True\n        else:\n            print(f\"✗ {name} returned status {response.status_code}\")\n            return False\n    except requests.exceptions.ConnectionError:\n        print(f\"✗ Cannot connect to {name} at {url}\")\n        print(\"  Contact your administrator if this persists\")\n        return False\n    except Exception as e:\n        print(f\"✗ Error checking {name}: {str(e)}\")\n        return False\n\nprint(\"\\nChecking API connectivity...\")\nsearch_healthy = check_service_health(TRIO_API_URL, \"Search API\")\n\nif search_healthy:\n    print(\"\\n✓ All systems ready!\")\nelse:\n    print(\"\\n⚠️  Search API is not available. Check the errors above.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Discover Available Cohorts\n\nBefore searching, you need to know which cohorts are indexed and available. The `/cohorts/indexed` endpoint lists all cohorts with searchable data in search index.\n\nEach indexed cohort includes:\n- `cohort_id` - Unique identifier\n- `cohort_name` - Human-readable name (if available)\n- `namespace` - search index namespace for the index\n- `chunk_count` - Number of indexed chunks (vectors)\n- `index_status` - Current indexing status"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_indexed_cohorts(limit: int = 20) -> List[Dict[str, Any]]:\n    \"\"\"\n    List all indexed cohorts available for search.\n\n    Args:\n        limit: Maximum number of cohorts to return (max 100)\n\n    Returns:\n        List of indexed cohort information\n    \"\"\"\n    response = requests.get(\n        f\"{TRIO_API_URL}/cohorts/indexed\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params={\"limit\": limit}\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        cohorts = data.get(\"items\", [])\n        total = data.get(\"total_count\", len(cohorts))\n        print(f\"Found {total} indexed cohorts (showing {len(cohorts)})\")\n        return cohorts\n    else:\n        print(f\"Failed to list cohorts: {response.status_code}\")\n        print(response.text)\n        return []\n\n# Fetch indexed cohorts\ncohorts = get_indexed_cohorts()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display cohorts as a formatted table\nif cohorts:\n    cohorts_df = pd.DataFrame(cohorts)\n\n    # Format the display\n    display_cols = [\"cohort_id\", \"cohort_name\", \"chunk_count\", \"index_status\"]\n    available_cols = [c for c in display_cols if c in cohorts_df.columns]\n\n    print(\"\\nIndexed Cohorts:\")\n    print(\"-\" * 80)\n    display(cohorts_df[available_cols].style.format({\n        \"chunk_count\": \"{:,}\"\n    }))\n\n    # Summary statistics\n    total_chunks = cohorts_df[\"chunk_count\"].sum()\n    print(f\"\\nTotal indexed chunks across all cohorts: {total_chunks:,}\")\nelse:\n    print(\"No cohorts available. Ensure data has been indexed.\")"
  },
  {
   "cell_type": "markdown",
   "id": "ak71f4bmcmp",
   "source": "## Step 2: Discover Note Types\n\nBefore filtering searches by note type, you can see what note types exist in the system. The `/note-types` endpoint provides a list of available note types.\n\nThis is useful for:\n- Understanding what documentation types are indexed\n- Filtering searches to specific note types (e.g., \"Progress Notes\", \"Discharge Summaries\")\n- Building UI dropdowns for note type selection",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ub52nc3find",
   "source": "def get_note_types(\n    search: Optional[str] = None,\n    limit: int = 50,\n    offset: int = 0\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    List available note types in the system.\n\n    Args:\n        search: Filter note types by name (case-insensitive substring match)\n        limit: Maximum number of results to return (default 50)\n        offset: Number of results to skip for pagination\n\n    Returns:\n        List of note type objects with id and name\n    \"\"\"\n    params = {\"limit\": limit, \"offset\": offset}\n    if search:\n        params[\"search\"] = search\n\n    response = requests.get(\n        f\"{TRIO_API_URL}/note-types\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params=params\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        note_types = data.get(\"items\", [])\n        total = data.get(\"total_count\", len(note_types))\n        print(f\"Found {total} note types (showing {len(note_types)})\")\n        return note_types\n    else:\n        print(f\"Failed to list note types: {response.status_code}\")\n        print(response.text)\n        return []\n\n# Fetch all note types\nnote_types = get_note_types()\n\n# Display as DataFrame\nif note_types:\n    note_types_df = pd.DataFrame(note_types)\n    print(\"\\nAvailable Note Types:\")\n    print(\"-\" * 60)\n    display(note_types_df)\nelse:\n    print(\"No note types found.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "00i2658rko7yq",
   "source": "# Filter note types by name\n# Example: Find all note types containing \"progress\"\nprogress_notes = get_note_types(search=\"progress\")\n\nif progress_notes:\n    print(\"\\nNote types matching 'progress':\")\n    for nt in progress_notes:\n        print(f\"  - {nt.get('name', 'Unknown')} (id: {nt.get('id', 'N/A')})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: Search a Cohort\n\nThe Search API supports three search modes:\n\n| Mode | Description | Best For |\n|------|-------------|----------|\n| `keyword` | BM25 full-text search | Exact terms, medical codes (e.g., \"ICD-10 E11.9\") |\n| `semantic` | Vector similarity search | Conceptual queries (e.g., \"patient struggling with blood sugar\") |\n| `hybrid` (default) | Combines both with reciprocal rank fusion | General-purpose queries |\n\n### Key Parameters\n\n- `query` (required) - Search text\n- `search-type` - Search mode (default: `hybrid`)\n- `k` - Number of results (default: 10, max: 300)\n- `cohort-ids` - Comma-separated cohort IDs to search\n- `rerank` - Apply Cohere reranking (default: true)\n- `distinct` - De-duplication mode: `encounter`, `patient`, `note`, or `none`\n- `vector-weight` - Weight for vector search in hybrid fusion (0.0-1.0)\n- `min-quality-score` - Minimum note quality score filter (0.0-1.0)\n- `filters` - search index attribute filters (JSON)\n- `entity-filters` - Entity and assertion filters (JSON)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def search(\n    query: str,\n    search_type: str = \"hybrid\",\n    k: int = 10,\n    cohort_ids: Optional[List[str]] = None,\n    rerank: bool = True,\n    date_from: Optional[str] = None,\n    date_to: Optional[str] = None,\n    note_types: Optional[List[str]] = None,\n    include_noise: bool = False,\n    distinct: Optional[str] = None,\n    vector_weight: Optional[float] = None,\n    top_k_retrieval: Optional[int] = None,\n    distance_threshold: Optional[float] = None,\n    chunk_multiplier: Optional[int] = None,\n    min_quality_score: Optional[float] = None,\n    min_chunk_quality_score: Optional[float] = None,\n    filters: Optional[Dict[str, Any]] = None,\n    entity_filters: Optional[Dict[str, Any]] = None,\n    **kwargs\n) -> Dict[str, Any]:\n    \"\"\"\n    Search indexed patient notes.\n\n    Args:\n        query: Search text\n        search_type: 'keyword', 'semantic', or 'hybrid' (default)\n        k: Number of results to return (max 300)\n        cohort_ids: List of cohort IDs to search\n        rerank: Apply Cohere reranking (default True, hybrid only)\n        date_from: Filter from date (YYYY-MM-DD)\n        date_to: Filter to date (YYYY-MM-DD)\n        note_types: Filter by note types\n        include_noise: Include noise notes (default False)\n        distinct: De-duplication mode ('encounter', 'patient', 'note', or 'none')\n        vector_weight: Weight for vector search in fusion (0.0-1.0, default 0.5)\n        top_k_retrieval: Number of results to retrieve before reranking\n        distance_threshold: Cosine distance cutoff for semantic results\n        chunk_multiplier: Initial retrieval multiplier for semantic search\n        min_quality_score: Minimum note quality score (0.0-1.0)\n        min_chunk_quality_score: Minimum chunk quality score (0.0-1.0)\n        filters: search index filters as dict (converted to JSON)\n        entity_filters: Entity/assertion filters as dict (converted to JSON)\n\n    Returns:\n        Search response with results and metadata\n    \"\"\"\n    params = {\n        \"query\": query,\n        \"search-type\": search_type,\n        \"k\": k,\n        \"rerank\": str(rerank).lower(),\n        \"include-noise\": str(include_noise).lower(),\n    }\n\n    if cohort_ids:\n        params[\"cohort-ids\"] = \",\".join(str(c) for c in cohort_ids)\n    if date_from:\n        params[\"date-from\"] = date_from\n    if date_to:\n        params[\"date-to\"] = date_to\n    if note_types:\n        params[\"note-types\"] = \",\".join(note_types)\n    if distinct:\n        params[\"distinct\"] = distinct\n    if vector_weight is not None:\n        params[\"vector-weight\"] = vector_weight\n    if top_k_retrieval is not None:\n        params[\"top-k-retrieval\"] = top_k_retrieval\n    if distance_threshold is not None:\n        params[\"distance-threshold\"] = distance_threshold\n    if chunk_multiplier is not None:\n        params[\"chunk-multiplier\"] = chunk_multiplier\n    if min_quality_score is not None:\n        params[\"min-quality-score\"] = min_quality_score\n    if min_chunk_quality_score is not None:\n        params[\"min-chunk-quality-score\"] = min_chunk_quality_score\n    if filters:\n        params[\"filters\"] = json.dumps(filters)\n    if entity_filters:\n        params[\"entity-filters\"] = json.dumps(entity_filters)\n\n    # Add any additional parameters\n    for key, value in kwargs.items():\n        params[key.replace(\"_\", \"-\")] = value\n\n    response = requests.get(\n        f\"{TRIO_API_URL}/search\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params=params\n    )\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Search failed: {response.status_code}\")\n        print(response.text)\n        return {\"results\": [], \"metadata\": {}}\n\n# Example search\nresults = search(\"diabetes management\", k=10)\nprint(f\"Found {len(results.get('results', []))} results\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(response: Dict[str, Any], show_text: bool = False):\n",
    "    \"\"\"Display search results in a formatted table.\"\"\"\n",
    "    results = response.get(\"results\", [])\n",
    "    metadata = response.get(\"metadata\", {})\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SEARCH RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Metadata summary\n",
    "    print(f\"\\nQuery: '{metadata.get('query', 'N/A')}'\")\n",
    "    print(f\"Search Type: {metadata.get('search_type', 'N/A')}\")\n",
    "    print(f\"Total Results: {metadata.get('total_results', 0)}\")\n",
    "    print(f\"Reranked: {metadata.get('reranked', False)}\")\n",
    "    print(f\"Distance Threshold: {metadata.get('distance_threshold', 'N/A')}\")\n",
    "\n",
    "    # Match counts\n",
    "    exact = metadata.get('exact_match_count')\n",
    "    semantic = metadata.get('semantic_match_count')\n",
    "    if exact is not None or semantic is not None:\n",
    "        print(f\"\\nMatch Counts:\")\n",
    "        if exact is not None:\n",
    "            print(f\"  Keyword (BM25): {exact:,}\")\n",
    "        if semantic is not None:\n",
    "            print(f\"  Semantic (Vector): {semantic:,}\")\n",
    "\n",
    "    # Unique counts\n",
    "    print(f\"\\nUnique Entities:\")\n",
    "    print(f\"  Patients: {metadata.get('unique_patients', 'N/A')}\")\n",
    "    print(f\"  Encounters: {metadata.get('unique_encounters', 'N/A')}\")\n",
    "    print(f\"  Notes: {metadata.get('unique_notes', 'N/A')}\")\n",
    "\n",
    "    # Omitted results (noise filtering)\n",
    "    omitted = metadata.get('omitted_results')\n",
    "    if omitted:\n",
    "        print(f\"\\nOmitted (Noise Filtered):\")\n",
    "        print(f\"  Semantic: {omitted.get('semantic_omitted', 0)}\")\n",
    "        print(f\"  Keyword: {omitted.get('keyword_omitted', 0)}\")\n",
    "        print(f\"  Total: {omitted.get('total_omitted', 0)}\")\n",
    "        if omitted.get('is_minimum'):\n",
    "            print(\"  (counts are minimum estimates)\")\n",
    "\n",
    "    # Results table\n",
    "    if results:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"TOP RESULTS\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        for i, result in enumerate(results[:5], 1):\n",
    "            print(f\"\\n{i}. Score: {result.get('score', 0):.4f}\")\n",
    "            print(f\"   Patient: {result.get('patient_id', 'N/A')[:20]}...\")\n",
    "            print(f\"   Note Type: {result.get('note_type', 'N/A')}\")\n",
    "            print(f\"   Note Date: {result.get('note_date', 'N/A')}\")\n",
    "\n",
    "            if result.get('distance') is not None:\n",
    "                print(f\"   Distance: {result['distance']:.4f}\")\n",
    "            if result.get('keyword_score') is not None:\n",
    "                print(f\"   Keyword Score: {result['keyword_score']:.4f}\")\n",
    "\n",
    "            if show_text:\n",
    "                text = result.get('text_chunk') or result.get('text_full', '')\n",
    "                if text:\n",
    "                    snippet = text[:200] + \"...\" if len(text) > 200 else text\n",
    "                    print(f\"   Snippet: {snippet}\")\n",
    "\n",
    "# Display results\n",
    "display_search_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6khuk3gg379",
   "source": "## Step 4: Adding Date Filters\n\nYou can filter search results by date range using:\n\n- `date-from` - Include notes from this date onwards (YYYY-MM-DD, inclusive)\n- `date-to` - Include notes up to this date (YYYY-MM-DD, inclusive)\n\nThis is useful for:\n- Finding recent documentation for a condition\n- Analyzing notes within a specific time period\n- Tracking progression of a condition over time",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7t3rt866j9a",
   "source": "# Example: Search with date range\n# Adjust dates based on your indexed data\n\n# Calculate date range (last 6 months)\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=180)\n\ndate_from = start_date.strftime(\"%Y-%m-%d\")\ndate_to = end_date.strftime(\"%Y-%m-%d\")\n\nprint(f\"Searching from {date_from} to {date_to}\")\n\n# Perform date-filtered search\ndate_results = search(\n    query=\"diabetes mellitus\",\n    k=20,\n    date_from=date_from,\n    date_to=date_to\n)\n\nprint(f\"\\nFound {len(date_results.get('results', []))} results in date range\")\ndisplay_search_results(date_results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "selb43ox9x",
   "source": "## Step 5: Entity and Assertion Filtering\n\nThe Search API can filter results based on extracted clinical entities and their assertion status. This is powerful for finding specific clinical mentions with context.\n\n### Entity Types\n\nClinical entities are extracted and categorized into these types:\n\n| Entity Type | Description | Examples |\n|-------------|-------------|----------|\n| `symptoms` | Patient-reported or observed symptoms | \"chest pain\", \"shortness of breath\" |\n| `diagnoses` | Medical diagnoses and conditions | \"diabetes mellitus\", \"hypertension\" |\n| `medications` | Drugs and medications | \"metformin\", \"lisinopril\" |\n| `procedures` | Medical procedures | \"colonoscopy\", \"cardiac catheterization\" |\n| `lab_tests` | Laboratory tests | \"HbA1c\", \"CBC\" |\n| `vital_signs` | Vital sign measurements | \"blood pressure\", \"heart rate\" |\n\n### Assertion Types\n\nEach entity has an assertion status indicating clinical context:\n\n| Assertion Type | Description | Example Context |\n|----------------|-------------|-----------------|\n| `present` | Currently present/active | \"Patient has diabetes\" |\n| `negated` | Explicitly negated | \"No chest pain\" |\n| `historical` | Past history | \"History of MI in 2019\" |\n| `family` | Family history | \"Mother had breast cancer\" |\n| `hypothetical` | Possible/uncertain | \"Rule out PE\" |\n| `conditional` | Conditional mention | \"If symptoms worsen\" |\n\n### Combining Entity and Assertion Types\n\nFilter keys combine entity type and assertion type with an underscore: `{entity_type}_{assertion_type}`\n\n**Examples:**\n- `symptoms_present` - Active symptoms\n- `diagnoses_negated` - Ruled-out diagnoses\n- `medications_historical` - Previously prescribed medications\n- `diagnoses_family` - Family history of conditions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jao7xqbcwm",
   "source": "# Example: Search for notes with specific entity filters\n# Find notes mentioning active diabetes symptoms\n\nentity_results = search(\n    query=\"diabetes\",\n    k=10,\n    entity_filters={\n        \"symptoms_present\": [\"fatigue\", \"polyuria\", \"polydipsia\"]\n    }\n)\n\nprint(f\"Found {len(entity_results.get('results', []))} results with diabetes-related symptoms\")\ndisplay_search_results(entity_results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "gasckmj3chh",
   "source": "## Step 6: Advanced Filters (search index Filters)\n\nFor complex filtering scenarios, you can pass raw search index filter expressions. These filters operate directly on indexed attributes and support various operators.\n\n### Filter Syntax\n\nFilters are passed as JSON objects with the following structure:\n\n```json\n{\n    \"field_name\": [\"value1\", \"value2\"],       // In list (OR)\n    \"field_name\": {\"$eq\": \"exact_value\"},     // Exact match\n    \"field_name\": {\"$ne\": \"excluded_value\"},  // Not equal\n    \"field_name\": {\"$in\": [\"a\", \"b\", \"c\"]},   // In list\n    \"field_name\": {\"$nin\": [\"x\", \"y\"]},       // Not in list\n    \"field_name\": {\"$gt\": 0.5},               // Greater than\n    \"field_name\": {\"$gte\": 0.5},              // Greater than or equal\n    \"field_name\": {\"$lt\": 1.0},               // Less than\n    \"field_name\": {\"$lte\": 1.0}               // Less than or equal\n}\n```\n\n### Common Filterable Fields\n\n- `note_type` - Type of clinical note\n- `quality_score` - Note quality score (0.0-1.0)\n- `chunk_quality_score` - Chunk quality score (0.0-1.0)\n- `patient_id` - Patient identifier\n- `encounter_id` - Encounter identifier",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ff0b8mh8m39",
   "source": "# Example: Using search index filters for quality score filtering\n# Find high-quality notes only\n\nhigh_quality_results = search(\n    query=\"diabetes management\",\n    k=10,\n    min_quality_score=0.7,  # Shortcut for quality score filter\n    min_chunk_quality_score=0.6\n)\n\nprint(f\"Found {len(high_quality_results.get('results', []))} high-quality results\")\ndisplay_search_results(high_quality_results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "o2djtjhqio",
   "source": "## Step 7: Filter Field Discovery\n\nBefore building complex filters, you can discover what filter fields are available and their possible values. This is useful for building dynamic filter UIs or understanding what data is indexed.\n\n### Endpoints\n\n- `GET /namespaces/{namespace}/filter-fields` - List available filter fields\n- `GET /namespaces/{namespace}/filter-values/{field}` - Get values for a specific field",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3o0fdbwl48y",
   "source": "def get_filter_fields(\n    namespace: str,\n    category: Optional[str] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    List available filter fields for a namespace.\n\n    Args:\n        namespace: search index namespace (from cohort info)\n        category: Filter by category (e.g., 'metadata', 'entity')\n\n    Returns:\n        List of filter field definitions\n    \"\"\"\n    params = {}\n    if category:\n        params[\"category\"] = category\n\n    response = requests.get(\n        f\"{TRIO_API_URL}/namespaces/{namespace}/filter-fields\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params=params\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        fields = data.get(\"fields\", [])\n        print(f\"Found {len(fields)} filter fields for namespace '{namespace}'\")\n        return fields\n    else:\n        print(f\"Failed to get filter fields: {response.status_code}\")\n        print(response.text)\n        return []\n\n\ndef get_filter_values(\n    namespace: str,\n    field: str,\n    limit: int = 50\n) -> List[Any]:\n    \"\"\"\n    Get possible values for a filter field.\n\n    Args:\n        namespace: search index namespace\n        field: Field name to get values for\n        limit: Maximum number of values to return\n\n    Returns:\n        List of possible values for the field\n    \"\"\"\n    response = requests.get(\n        f\"{TRIO_API_URL}/namespaces/{namespace}/filter-values/{field}\",\n        headers={\"X-API-Key\": TRIO_API_KEY},\n        params={\"limit\": limit}\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        values = data.get(\"values\", [])\n        total = data.get(\"total_count\", len(values))\n        print(f\"Found {total} values for field '{field}' (showing {len(values)})\")\n        return values\n    else:\n        print(f\"Failed to get filter values: {response.status_code}\")\n        print(response.text)\n        return []",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yk455sk53y",
   "source": "# Example: Discover filter fields for a cohort\n# First, get a namespace from an indexed cohort\n\nif cohorts:\n    # Use the first cohort's namespace\n    example_namespace = cohorts[0].get(\"namespace\")\n    \n    if example_namespace:\n        print(f\"Exploring filter fields for namespace: {example_namespace}\\n\")\n        \n        # Get all available filter fields\n        fields = get_filter_fields(example_namespace)\n        \n        if fields:\n            fields_df = pd.DataFrame(fields)\n            print(\"\\nAvailable Filter Fields:\")\n            print(\"-\" * 60)\n            display(fields_df)\n    else:\n        print(\"No namespace found in cohort data\")\nelse:\n    print(\"No cohorts available. Run the cohorts cell first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "foqovk6liov",
   "source": "# Example: Get possible values for a specific filter field\n# This is useful for building filter dropdowns in UIs\n\nif cohorts:\n    example_namespace = cohorts[0].get(\"namespace\")\n    \n    if example_namespace:\n        # Get values for note_type field\n        print(\"Getting values for 'note_type' field...\\n\")\n        note_type_values = get_filter_values(example_namespace, \"note_type\", limit=20)\n        \n        if note_type_values:\n            print(\"\\nAvailable note_type values:\")\n            for i, value in enumerate(note_type_values, 1):\n                print(f\"  {i}. {value}\")\nelse:\n    print(\"No cohorts available. Run the cohorts cell first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "nzs87129n8",
   "source": "## Step 8: Comparing Search Types\n\nDifferent search types excel at different tasks:\n\n| Search Type | Strengths | Weaknesses |\n|-------------|-----------|------------|\n| **Keyword** | Exact matches, medical codes, specific terminology | Misses synonyms, conceptual matches |\n| **Semantic** | Conceptual similarity, synonyms, paraphrasing | May miss exact term matches |\n| **Hybrid** | Best of both worlds | Slightly more latency |\n\nLet's compare results for the same query across all three modes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "l8aos42jug",
   "source": "def compare_search_types(query: str, k: int = 10) -> Dict[str, Dict]:\n    \"\"\"Run the same query across all search types and compare.\"\"\"\n    search_types = [\"keyword\", \"semantic\", \"hybrid\"]\n    results = {}\n\n    for stype in search_types:\n        print(f\"Running {stype} search...\")\n        results[stype] = search(query, search_type=stype, k=k, rerank=(stype == \"hybrid\"))\n\n    return results\n\n# Compare search types\nquery = \"patient with elevated blood glucose\"\ncomparison = compare_search_types(query, k=20)\n\n# Display comparison summary\nprint(\"\\n\" + \"=\" * 80)\nprint(\"SEARCH TYPE COMPARISON\")\nprint(\"=\" * 80)\nprint(f\"Query: '{query}'\\n\")\n\nfor stype, result in comparison.items():\n    meta = result.get(\"metadata\", {})\n    print(f\"\\n{stype.upper()} Search:\")\n    print(f\"  Results returned: {meta.get('total_results', 0)}\")\n    if meta.get('exact_match_count') is not None:\n        print(f\"  Keyword matches: {meta.get('exact_match_count', 'N/A'):,}\")\n    if meta.get('semantic_match_count') is not None:\n        print(f\"  Semantic matches: {meta.get('semantic_match_count', 'N/A'):,}\")\n    print(f\"  Unique patients: {meta.get('unique_patients', 'N/A')}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1wa8ya441jk",
   "source": "## Step 9: Visualizing Search Results\n\nThis section provides visualizations to help analyze search results:\n\n1. **Omission Analysis** - Impact of noise filtering\n2. **Ranking Metrics** - Vector vs BM25 ranking contribution",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jb54tzf3fb9",
   "source": "def visualize_omitted_results(response: Dict[str, Any]):\n    \"\"\"Visualize omitted (noise-filtered) results.\"\"\"\n    metadata = response.get(\"metadata\", {})\n    omitted = metadata.get(\"omitted_results\")\n\n    if not omitted:\n        print(\"No omission data available (noise filtering may be disabled or skipped)\")\n        return\n\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n    # Left: Omitted by type\n    ax1 = axes[0]\n    omit_types = []\n    omit_counts = []\n\n    if omitted.get(\"semantic_omitted\") is not None:\n        omit_types.append(\"Semantic\\nOmitted\")\n        omit_counts.append(omitted[\"semantic_omitted\"])\n    if omitted.get(\"keyword_omitted\") is not None:\n        omit_types.append(\"Keyword\\nOmitted\")\n        omit_counts.append(omitted[\"keyword_omitted\"])\n\n    if omit_types:\n        colors = ['#c0392b', '#d35400']\n        bars = ax1.bar(omit_types, omit_counts, color=colors, edgecolor='black')\n        ax1.set_ylabel('Omitted Count')\n        ax1.set_title('Results Filtered as Noise')\n\n        for bar in bars:\n            height = bar.get_height()\n            ax1.annotate(f'{int(height):,}',\n                        xy=(bar.get_x() + bar.get_width() / 2, height),\n                        xytext=(0, 3), textcoords=\"offset points\",\n                        ha='center', va='bottom', fontsize=10)\n\n    # Right: Included vs Omitted pie chart\n    ax2 = axes[1]\n    total_results = metadata.get(\"total_results\", 0)\n    total_omitted = omitted.get(\"total_omitted\", 0)\n\n    if total_results > 0 or total_omitted > 0:\n        sizes = [total_results, total_omitted]\n        labels = [f'Included\\n({total_results:,})', f'Omitted\\n({total_omitted:,})']\n        colors = ['#27ae60', '#e74c3c']\n        explode = (0, 0.05)\n\n        ax2.pie(sizes, explode=explode, labels=labels, colors=colors,\n               autopct='%1.1f%%', shadow=True, startangle=90)\n        ax2.set_title('Results Distribution')\n\n    plt.tight_layout()\n    plt.show()\n\n# Visualize omission data from earlier search\nif results.get(\"results\"):\n    visualize_omitted_results(results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ranking_metrics(response: Dict[str, Any]):\n",
    "    \"\"\"Visualize ranking metrics (vector_rank, bm25_rank) when available.\"\"\"\n",
    "    results = response.get(\"results\", [])\n",
    "    metadata = response.get(\"metadata\", {})\n",
    "\n",
    "    # Check if fusion details are available (requires rerank=false)\n",
    "    if metadata.get(\"reranked\", True):\n",
    "        print(\"Ranking details are only available when rerank=false\")\n",
    "        print(\"Run: search(query, rerank=False)\")\n",
    "        return\n",
    "\n",
    "    # Extract ranking data\n",
    "    ranking_data = []\n",
    "    for i, r in enumerate(results):\n",
    "        if r.get(\"vector_rank\") is not None or r.get(\"bm25_rank\") is not None:\n",
    "            ranking_data.append({\n",
    "                \"result_position\": i + 1,\n",
    "                \"vector_rank\": r.get(\"vector_rank\"),\n",
    "                \"bm25_rank\": r.get(\"bm25_rank\"),\n",
    "                \"fusion_score\": r.get(\"fusion_score\", 0)\n",
    "            })\n",
    "\n",
    "    if not ranking_data:\n",
    "        print(\"No ranking data available in results\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(ranking_data)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Left: Vector vs BM25 rank scatter\n",
    "    ax1 = axes[0]\n",
    "    scatter = ax1.scatter(\n",
    "        df[\"vector_rank\"].fillna(df[\"vector_rank\"].max() + 10),\n",
    "        df[\"bm25_rank\"].fillna(df[\"bm25_rank\"].max() + 10),\n",
    "        c=df[\"fusion_score\"],\n",
    "        cmap='viridis',\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolor='black'\n",
    "    )\n",
    "    ax1.set_xlabel('Vector Rank')\n",
    "    ax1.set_ylabel('BM25 Rank')\n",
    "    ax1.set_title('Vector vs BM25 Ranking')\n",
    "    plt.colorbar(scatter, ax=ax1, label='Fusion Score')\n",
    "\n",
    "    # Right: Rank contribution to final position\n",
    "    ax2 = axes[1]\n",
    "    positions = df[\"result_position\"]\n",
    "    ax2.plot(positions, df[\"vector_rank\"], 'o-', label='Vector Rank', color='teal')\n",
    "    ax2.plot(positions, df[\"bm25_rank\"], 's-', label='BM25 Rank', color='coral')\n",
    "    ax2.set_xlabel('Final Result Position')\n",
    "    ax2.set_ylabel('Original Rank')\n",
    "    ax2.set_title('Rank Contribution to Final Position')\n",
    "    ax2.legend()\n",
    "    ax2.invert_yaxis()  # Lower rank = better\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run a search without reranking to see fusion details\n",
    "unranked_results = search(\"diabetes\", k=15, rerank=False)\n",
    "visualize_ranking_metrics(unranked_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r7d33wp59xm",
   "source": "## Summary\n\nIn this notebook, you learned how to:\n\n1. **Configure Authentication** - Set up your API key for secure access\n2. **Discover Cohorts** - List indexed cohorts available for search\n3. **Discover Note Types** - Find available note types for filtering\n4. **Search Notes** - Use keyword, semantic, and hybrid search modes\n5. **Apply Date Filters** - Filter by date range\n6. **Use Entity Filters** - Filter by clinical entities and assertion types\n7. **Use Advanced Filters** - Apply search index attribute filters and quality thresholds\n8. **Discover Filter Fields** - Explore available filter fields and their values\n9. **Compare Search Types** - Understand when to use each search mode\n10. **Visualize Results** - Analyze search results with charts and metrics\n\n## Key API Endpoints\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/health` | GET | Health check |\n| `/cohorts/indexed` | GET | List indexed cohorts |\n| `/note-types` | GET | List available note types |\n| `/search` | GET | Search notes with filters |\n| `/namespaces/{ns}/filter-fields` | GET | List filter fields for a namespace |\n| `/namespaces/{ns}/filter-values/{field}` | GET | Get values for a filter field |\n\n## Search Parameters Quick Reference\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string | Search text (required) |\n| `search-type` | string | `keyword`, `semantic`, or `hybrid` |\n| `k` | int | Number of results (max 300) |\n| `cohort-ids` | string | Comma-separated cohort IDs |\n| `rerank` | bool | Apply Cohere reranking |\n| `distinct` | string | De-duplication: `encounter`, `patient`, `note`, `none` |\n| `date-from` / `date-to` | string | Date range filter (YYYY-MM-DD) |\n| `note-types` | string | Comma-separated note types |\n| `vector-weight` | float | Vector weight in fusion (0.0-1.0) |\n| `min-quality-score` | float | Minimum note quality (0.0-1.0) |\n| `filters` | JSON | search index attribute filters |\n| `entity-filters` | JSON | Entity/assertion type filters |\n\n## Next Steps\n\n- Explore the Search API documentation\n- Check out the CLI tool: `trioexplorer --help`\n- Experiment with different search types and parameters\n- Build custom filters using the filter discovery endpoints\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Connection refused** - Contact your administrator to verify the API endpoints\n\n2. **401 Unauthorized** - Check your API key is valid and has correct entitlements\n\n3. **No cohorts found** - Data may not be indexed yet or your API key may not have access\n\n4. **Slow searches** - Try reducing `k` or disabling `rerank` for faster results\n\n5. **Empty filter values** - The namespace may not have data indexed for that field",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}